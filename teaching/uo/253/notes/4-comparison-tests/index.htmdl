### nav-buttons

Our next test for convergence isn't nearly so complicated. Now that we know the behavior of a few series, like all of the $p$-series, we can also determine how other closely related series behave. The Squeeze theorem for sequences states that if $a_n \geq b_n$ for all $n \geq N$ for some integer $N$, then $\lim (a_n) \geq \lim (b_n)$, assuming both limits exist. Applying this to the sequence of partial sums for two series gives us the following straightforward result.



### prop "the comparison test"
	
	Let $\sum_{n = 1}^\infty a_n$ and $\sum_{n = 1}^\infty b_n$ be two series with $a_n \geq b_n \geq 0$ for all $n \geq N$ for some integer $N$. Then:
	
	1. If $\sum_{n = 1}^\infty a_n$ converges, then $\sum_{n = 1}^\infty b_n$ also converges.
	
	2. If $\sum_{n = 1}^\infty b_n$ diverges, then $\sum_{n = 1}^\infty b_n$ also diverges.
	
###



The idea isn't too tricky: if you start with a convergent series with positive terms and make every term smaller, the new series will still converge. Similarly, taking a divergent series with positive terms and making every term larger results in a series that still diverges. We need the terms to all be positive so that the partial sums of both series have the same inequalities as the terms themselves.



### ex "the comparison test"
	
	show that $$\sum_{n = 1}^\infty \frac{1}{n^2 + 20}$$ converges.
	
	While we could use the integral test, it would require trig sub, and that's probably something to be avoided if possible. Instead, this looks a whole lot like $\sum_{n = 1}^\infty \frac{1}{n^2}$, a series we already know converges. Increasing a denominator decreases the overall fraction, so
	
	$$
		\frac{1}{n^2 + 20} \leq \frac{1}{n^2}
	$$
	
	for all $n$. Since all the terms are positive and smaller than a series known to converge, our series $\sum_{n = 1}^\infty \frac{1}{n^2 + 20}$ must also converge by the comparison test.
	
###

### exc "the comparison test"
	
	Use the comparision test to determine if the following series converge or diverge.
	
	1. $$\sum_{n = 1}^\infty \frac{1}{n^4 + n^3}$$.
	
	2. $$\sum_{m = 2}^\infty \frac{1}{\ln(m)}$$.
	
	3. $$\sum_{n = 1}^\infty \frac{1}{2^n + 3}$$.
	
	**Solutions:**
	
	1. The denominator is dominated by $n^4$, so let's try to compare against that. We need
	
	$$
		\frac{1}{n^4 + n^3} &\leq \frac{1}{n^4}
		
		n^4 + n^3 &\geq n^4
		
		n^3 &\geq 0
		
		n^3 &\geq 0,
	$$
	
	which is always true since $n \geq 1$. Since $\sum_{n = 1}^\infty \frac{1}{n^4}$ is a $p$-series with $p = 4 > 1$, it converges, so by the comparison test, so does $\sum_{n = 1}^\infty \frac{1}{n^4 + n^3}$.
	
	2. This one is a little more tricky. We usually want to compare against a $p$-series or geometric series, but this doesn't look like either. However, since $\ln(m)$ is growing incredibly slowly, significantly slower than $m$, we might expect it to diverge. To that end, let's try to compare it to $\sum_{m = 2}^\infty \frac{1}{m}$. For it to succeed, we need
	
	$$
		\frac{1}{\ln(m)} &\geq \frac{1}{m}
		
		\ln(m) & \leq m
		
		m &\leq e^m,
	$$
	
	which is true for $m \geq 0$. Therefore, the comparison test applies, and since $\sum_{m = 2}^\infty \frac{1}{m}$ is (except for the first term) the Harmonic series, $\sum_{m = 2}^\infty \frac{1}{\ln(m)}$ diverges.
	
	3. The denominator is dominated by $2^n$, so let's try comparing against $\sum_{n = 1}^\infty \frac{1}{2^n}$. Since that is a geometric series with base $\frac{1}{2}$, it converges, so we need to show
	
	$$
		\frac{1}{2^n + 3} &\leq \frac{1}{2^n}
		
		2^n + 3 &\geq 2^n
		
		3 &\geq 0.
	$$
	
	Therefore, this is always true, and so $\sum_{n = 1}^\infty \frac{1}{2^n + 3}$ converges.
	
###



Although it's easy enough to understand and use, the comparison test tends to fall apart in situations that don't seem particularly complicated. A series like

$$
	\sum_{n = 1}^\infty \frac{1}{n^2 - \frac{1}{2}}
$$

is too much for it to handle. The only series we have a hope of comparing it to is $\sum_{n = 1}^\infty \frac{1}{n^2}$, but since all the terms are larger, the comparision test doesn't tell us anything.

After two full terms of calculus, though, you might have a sense of what this series ought to do --- since it only differs by a constant in the denominator, $\frac{1}{n^2 - \frac{1}{2}}$ isn't *that* much larger than $\frac{1}{n^2}$. Compared to something like $\sum_{n = 1}^\infty \frac{1}{n}$, whose terms decrease at a fundamentally slower rate, the terms of $\sum_{n = 1}^\infty \frac{1}{n^2 - \frac{1}{2}}$ decay at a rate nearly identical to $\sum_{n = 1}^\infty \frac{1}{n^2}$, so it feels like it still ought to converge. Thankfully, those two terms of calculus have given us the language to be precise about that feeling.

Two positive functions $f(x)$ and $g(x)$ have fundamentally different rates of growth when either $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 0$ or $\infty$. In the first case, $g$ grows much faster than $f$, and in the second case, $f$ much faster than $g$. For example, with $f(x) = x^2 + 1$ and $g(x) = x$, we have

$$
	\lim_{x \to \infty} \frac{f(x)}{g(x)} &= \lim_{x \to \infty} \frac{\frac{d}{dx} [x^2 + 1]}{\frac{d}{dx} [x]}
	
	&= \lim_{x \to \infty} \frac{2x}{1}
	
	&= \infty.
$$

On the other hand, if $\lim_{x \to \infty} \frac{f(x)}{g(x)} = L$ for some $L$ that is neither $0$ nor $\infty$, then $f$ and $g$ grow at proportional rates, like with $f(x) = 2x^2 + 1$ and $g(x) = x^2$. In this case, $\lim_{x \to \infty} \frac{f(x)}{g(x)} = 2$, which means that for large $x$, $f(x) \approx 2g(x)$.

The same logic applies to the terms of a series. For positive $a_n$ and $b_n$, if $\lim_{n \to \infty} \frac{a_n}{b_n} = L$ for $L \neq 0$ and $L \neq \infty$, then $a_n \approx Lb_n$ for large $n$, say for all $n \geq N$ for some large integer $N$. That means

$$
	\sum_{n = N}^\infty a_n \approx \sum_{n = N}^\infty Lb_n = L\sum_{n = N}^\infty b_n.
$$

Since the two series differ approximately only by a constant multiple, they either both converge or both diverge. Moreover, even if $\lim_{n \to \infty} \frac{a_n}{b_n}$ is $0$ or $\infty$, we can still extract some information. If the limit is zero, then $a_n$ grows at a much slower rate than $b_n$. Therefore, if $\sum_{n = 1}^\infty b_n$ converges, then so does $\sum_{n = 1}^\infty a_n$. Similarly, if $\lim_{n \to \infty} \frac{a_n}{b_n} = \infty$ and $\sum_{n = 1}^\infty b_n$ diverges, then $\sum_{n = 1}^\infty a_n$ must also diverge, since $a_n$ grows at a much faster rate than $b_n$.

In our example, we're trying to compare $\frac{1}{n^2 - \frac{1}{2}}$ to $\frac{1}{n^2}$. We'll take $a_n = \frac{1}{n^2 - \frac{1}{2}}$ and $b_n = \frac{1}{n^2}$ and examine $\lim_{n \to \infty} \frac{a_n}{b_n}$.

$$
	\lim_{n \to \infty} \frac{a_n}{b_n} &= \lim_{n \to \infty} \frac{\frac{1}{n^2 - \frac{1}{2}}}{\frac{1}{n^2}}
	
	&= \lim_{n \to \infty} \frac{n^2}{n^2 - \frac{1}{2}}
	
	&= \lim_{n \to \infty} \frac{\frac{d}{dn}[n^2]}{\frac{d}{dn}\left[n^2 - \frac{1}{2}\right]}
	
	&= \lim_{n \to \infty} \frac{2n}{2n}
	
	&= 1.
$$

Since the limit is neither $0$ nor $\infty$, the two series behave identically. Therefore, since $\sum_{n = 1}^\infty \frac{1}{n^2}$ converges, so does $\sum_{n = 1}^\infty \frac{1}{n^2 - \frac{1}{2}}$.

Let's state the general form of this result, and then we'll work through some examples.



### thm "the limit comparison test"
	
	Let $\sum_{n = 1}^\infty a_n$ and $\sum_{n = 1}^\infty b_n$ be two series with $a_n \geq 0$ and $b_n \geq 0$, and let $L = \lim_{n \to \infty} \frac{a_n}{b_n}$.
	
	1. If $L \neq 0$ and $L \neq \infty$, then $\sum_{n = 1}^\infty a_n$ and $\sum_{n = 1}^\infty b_n$ either both converge or both diverge.
	
	2. If $L = 0$ and $\sum_{n = 1}^\infty b_n$ converges, then $\sum_{n = 1}^\infty a_n$ also converges.
	
	3. If $L = \infty$ and $\sum_{n = 1}^\infty b_n$ diverges, then $\sum_{n = 1}^\infty a_n$ also diverges.
	
	4. If $L$ does not exist, then the test is inconclusive.
	
###



If you're asked to determine if a given series converges, try the divergence test first. If it's inconclusive, see if the terms are close enough to another series that one of the two comparison tests applies. If not, then give the integral test a shot. If you're asked to estimate error, you'll have to use the integral test straight off, since that's the only one we know with error estimation so far. Finally, all of our tests other than the divergence test require the terms of the series to eventually all be positive. We'll discuss series with negative terms in future sections, but for now, we have almost no tools to determine their behavior.



### ex "the limit comparison test"
	
	Determine if $$\sum_{n = 1}^\infty \frac{2^n + 3^n}{4^n}$$ converges or diverges.
	
	Let's run through our list of tests. The divergence test is almost always the easiest, so let's start there. We have
	
	$$
		\lim_{n \to \infty} \frac{2^n + 3^n}{4^n} &= \lim_{n \to \infty} \left( \frac{2^n}{4^n} + \frac{3^n}{4^n} \right)
		
		&= \lim_{n \to \infty} \left( \left( \frac{1}{2} \right)^n + \left( \frac{3}{4} \right)^n \right)
		
		&= 0.
	$$
	
	Therefore, the test is inconclusive. By the guidance we mentioned earlier, we should now try to apply one of the comparison tests. For large $n$, $3^n$ is much larger than $2^n$, so we'd expect the behavior of the fraction to look like $\frac{3^n}{4^n}$. Unfortunately, this means the regular comparison test is probably out --- to apply it against $\frac{3^n}{4^n}$, we'd need the terms of our series to each be less than $\frac{3^n}{4^n}$, but they're larger. Therefore, let's give the limit comparison test a shot. We divide our terms, $\frac{2^n + 3^n}{4^n}$, by the terms we're comparing against, to get
	
	$$
		\lim_{n \to \infty} \frac{\frac{2^n + 3^n}{4^n}}{\frac{3^n}{4^n}} &= \lim_{n \to \infty} \frac{2^n + 3^n}{3^n}
		
		&= \lim_{n \to \infty} \left( \frac{2^n}{3^n} + 1 \right)
		
		&= \lim_{n \to \infty} \left( \left( \frac{2}{3} \right)^n + 1 \right)
		
		&= 0 + 1
		
		&= 1.
	$$
	
	Since this limit exists and is neither zero nor $\infty$, we know that the behavior of the two series is identical. The series we chose to compare against is a geometric series with a base between $-1$ and $1$, so it converges:
	
	$$
		\sum_{n = 1}^\infty \frac{3^n}{4^n} &= -1 + \sum_{n = 0}^\infty \left( \frac{3}{4} \right)^n
		
		&= -1 + \frac{1}{1 - \frac{3}{4}}
		
		&= 3.
	$$
	
	While we don't know what $\sum_{n = 1}^\infty \frac{2^n + 3^n}{4^n}$ converges <em>to</em>, we do know that it must converge.
	
###

### exc "the limit comparison test"
	
	Determine if the following series converge or diverge.
	
	1. $$\sum_{n = 1}^\infty \frac{2^n - n}{3^n}$$.
	
	2. $$\sum_{n = 1}^\infty \frac{2}{\sqrt{n} + 10}$$.
	
	3. $$\sum_{k = 1}^\infty \frac{k^2}{k(k + 3)}$$.
	
	4. $$\sum_{n = 1}^\infty \frac{\ln(n)}{n}$$.
	
	**Solutions:**
	
	1. In the limit, the terms look like $\frac{2^n}{3^n} = \left(\frac{2}{3}\right)^n$, so we might try comparing against that. It's worth trying the regular comparison test first: since we're subtracting $n$, a positive number, from the numerator, the entire fraction is made smaller, so we have
	
	$$
		\frac{2^n - n}{3^n} \leq \frac{2^n}{3^n}.
	$$
	
	Since $\sum_{n = 1}^\infty \left(\frac{2}{3}\right)^n$ is a geometric series with $r = \frac{2}{3}$, it converges, so the same is true of $\sum_{n = 1}^\infty \frac{2^n - n}{3^n}$ by the comparison test.
	
	2. For large $n$, the terms look like $\frac{2}{\sqrt{n}}$. Those form a $p$-series with $p = \frac{1}{2} \leq 1$, which is divergent. To use the regular comparison test, we'd need every term to be larger, but since the denominator is being increased, we have the opposite. Therefore, let's try the limit comparison test. We have
	
	$$
		\lim_{n \to \infty} \frac{\frac{2}{\sqrt{n} + 10}}{\frac{2}{\sqrt{n}}} &= \lim_{n \to \infty} \frac{\sqrt{n}}{\sqrt{n} + 10}
		
		&= 1
	$$
	
	by L'H&#244;pital's rule. The series therefore have the same behavior, so $\sum_{n = 1}^\infty \frac{2}{\sqrt{n} + 10}$ diverges.
	
	3. Multiplying out the denominator, these terms look like $\frac{k^2}{k^2} = 1$ in the limit. That's a clue that this series probably fails the divergence test, and so we don't even need to compare against anything. Properly taking the limit of the terms gives us
	
	$$
		\lim_{k \to \infty} \frac{k^2}{k^2 + 3k} = 1 \neq 0
	$$
	
	since it's a ratio of polynomials, and so it does in fact fail, meaning the series must diverge.
	
	4. It's possible to get the regular comparison test to work here, but it's a little annoying --- most of the time, $\ln(n) > 1$, so we can compare against the Harmonic series, but that's not true when $n = 1$, since $\ln(1) = 0$. Let's try the limit comparison test just to save ourselves a headache. We have
	
	$$
		\lim_{n \to \infty} \frac{\frac{\ln(n)}{n}}{\frac{1}{n}} &= \lim_{n \to \infty} \ln(n)
		
		&= \infty.
	$$
	
	Since we're comparing against a divergent series, our series must be divergent too.
	
###


	
### nav-buttons