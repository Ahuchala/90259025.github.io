<header><div id="logo"><a href="/home/" tabindex="-1"><img src="/graphics/general-icons/logo.webp" alt="Logo" tabindex="1"></img></a></div><div style="height: 20px"></div><h1 class="heading-text">Section 12: Complex and Repeated Eigenvectors</h1></header><main><section><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div><p class="body-text">So far, we know how to handle systems of the form <span class="tex-holder inline-math" data-source-tex="\mathbf{x}' = \mathbf{Ax}">$\mathbf{x}' = \mathbf{Ax}$</span> when the eigenvalues of <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> are real and distinct. Just like with <span class="tex-holder inline-math" data-source-tex="n">$n$th-order</span> individual DEs, we&#x2019;ll now work on extending that to all matrices <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$,</span> regardless of the eigenvalues.</p></section><h2 class="section-text">Complex Eigenvalues</h2><section><p class="body-text">Much like we only discussed <span class="tex-holder inline-math" data-source-tex="n">$n$th-order</span> DEs with real coefficients, we&#x2019;ll only be considering matrices with real entries. That means the characteristic polynomials will have only real coefficients, and so any complex eigenvalues will come in conjugate pairs. If <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> has eigenvalues of <span class="tex-holder inline-math" data-source-tex="\lambda = \alpha \pm \beta i">$\lambda = \alpha \pm \beta i$</span> corresponding to eigenvectors <span class="tex-holder inline-math" data-source-tex="\mathbf{v_+}">$\mathbf{v_+}$</span> and <span class="tex-holder inline-math" data-source-tex="\mathbf{v_-}">$\mathbf{v_-}$,</span> then</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{A}\mathbf{v_+} &= \left(\alpha + \beta i \right) \mathbf{v_+}.[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{A}\mathbf{v_+} &= \left(\alpha + \beta i \right) \mathbf{v_+}.\end{align*}$$</span></p><p class="body-text">Let&#x2019;s now take the complex conjugate of both sides (flipping the sign of any imaginary number), which is typically indicated by putting a bar above a variable.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\overline{\mathbf{A}\mathbf{v_+}} &= \overline{\left(\alpha + \beta i \right) \mathbf{v_+}}.[NEWLINE]\end{align*}">$$\begin{align*}\overline{\mathbf{A}\mathbf{v_+}} &= \overline{\left(\alpha + \beta i \right) \mathbf{v_+}}.\end{align*}$$</span></p><p class="body-text">For reasons slightly out of scope of this class, conjugation splits across multiplication, so we have</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\overline{\mathbf{A}} \overline{\mathbf{v_+}} &= \overline{\left(\alpha + \beta i \right)} \overline{\mathbf{v_+}}.[NEWLINE]\end{align*}">$$\begin{align*}\overline{\mathbf{A}} \overline{\mathbf{v_+}} &= \overline{\left(\alpha + \beta i \right)} \overline{\mathbf{v_+}}.\end{align*}$$</span></p><p class="body-text">Finally, <span class="tex-holder inline-math" data-source-tex="\overline{\alpha + \beta i} = \alpha - \beta i">$\overline{\alpha + \beta i} = \alpha - \beta i$,</span> and <span class="tex-holder inline-math" data-source-tex="\overline{\mathbf{A}} = \mathbf{A}">$\overline{\mathbf{A}} = \mathbf{A}$,</span> since all the entries of <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> are real by assumption. Therefore,</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{A} \overline{\mathbf{v_+}} &= \left(\alpha - \beta i \right) \overline{\mathbf{v_+}}.[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{A} \overline{\mathbf{v_+}} &= \left(\alpha - \beta i \right) \overline{\mathbf{v_+}}.\end{align*}$$</span></p><p class="body-text">But that&#x2019;s exactly what it means to be <span class="tex-holder inline-math" data-source-tex="\mathbf{v_-}">$\mathbf{v_-}$!</span> What we&#x2019;ve shown is that if <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> has real entries, then it&#x2019;s not just its eigenvalues that come in conjugate pairs &mdash; the corresponding eigenvectors do too.</p><p class="body-text">With individual DEs, we were able to extract two fundamental solutions immediately from a pair of conjugate roots to the characteristic equation by taking the real and imaginary parts of a single one of the two solutions, and we&#x2019;ll do the same here. Let&#x2019;s work through an example to see this all in action.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: complex eigenvalues</div><p class="body-text">A species of fish in a pond feeds primarily on a certain strain of algae &mdash; with <span class="tex-holder inline-math" data-source-tex="p_1(t)">$p_1(t)$</span> and <span class="tex-holder inline-math" data-source-tex="p_2(t)">$p_2(t)$</span> giving the total biomass of fish and algae in <span class="tex-holder inline-math" data-source-tex="\text{kg}">$\text{kg}$</span> after <span class="tex-holder inline-math" data-source-tex="t">$t$</span> days, respectively, they satisfy the system</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]p_1' &= p_1 + p_2\\[NEWLINE][TAB]p_2' &= -2p_1 + 3p_2.[NEWLINE]\end{align*}">$$\begin{align*}p_1' &= p_1 + p_2\\[4px]p_2' &= -2p_1 + 3p_2.\end{align*}$$</span></p><p class="body-text">At time <span class="tex-holder inline-math" data-source-tex="t = 0">$t = 0$,</span> there are <span class="tex-holder inline-math" data-source-tex="100\,\text{kg}">$100\,\text{kg}$</span> of both fish and algae. Find <span class="tex-holder inline-math" data-source-tex="\mathbf{p}">$\mathbf{p}$</span> as a function of <span class="tex-holder inline-math" data-source-tex="t">$t$</span> and sketch a vector field.</p><p class="body-text">This problem proceeds familiarly, but we&#x2019;ll have the added wrinkle of complex eigenvalues. To get started, let&#x2019;s write it as a matrix.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{p}' = \left[\begin{array}{cc} 1& 1 \\ -2& 3 \end{array}\right] \mathbf{p}.[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{p}' = \left[\begin{array}{cc} 1& 1 \\ -2& 3 \end{array}\right] \mathbf{p}.\end{align*}$$</span></p><p class="body-text">Calling that matrix <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$,</span> we first need to solve <span class="tex-holder inline-math" data-source-tex="\det (\mathbf{A} - \lambda \mathbf{I}) = 0">$\det (\mathbf{A} - \lambda \mathbf{I}) = 0$.</span> That gives us</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\det \left[\begin{array}{cc} 1 - \lambda& 1 \\ -2& 3 - \lambda \end{array}\right] &= 0\\[NEWLINE][TAB](1 - \lambda)(3 - \lambda) - (1)(-2) &= 0\\[NEWLINE][TAB]\lambda^2 - 4\lambda + 5 &= 0\\[NEWLINE][TAB]\lambda &= \frac{4 \pm \sqrt{16 - 20}}{2}\\[NEWLINE][TAB]\lambda &= \frac{4 \pm 2i}{2}\\[NEWLINE][TAB]\lambda &= 2 \pm i.[NEWLINE]\end{align*}">$$\begin{align*}\det \left[\begin{array}{cc} 1 - \lambda& 1 \\ -2& 3 - \lambda \end{array}\right] &= 0\\[4px](1 - \lambda)(3 - \lambda) - (1)(-2) &= 0\\[4px]\lambda^2 - 4\lambda + 5 &= 0\\[4px]\lambda &= \frac{4 \pm \sqrt{16 - 20}}{2}\\[4px]\lambda &= \frac{4 \pm 2i}{2}\\[4px]\lambda &= 2 \pm i.\end{align*}$$</span></p><p class="body-text">That&#x2019;s the eigenvalues done &mdash; now we need to find the corresponding eigenvectors. Let&#x2019;s start with <span class="tex-holder inline-math" data-source-tex="\lambda = 2 + i">$\lambda = 2 + i$</span> &mdash; we haven&#x2019;t had to deal with row reducing a complex-values matrix before, but it takes a little bit of care: in general, we want to avoid dividing by imaginary numbers even more than we want to avoid dividing by real ones.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc|c} 1 - (2 + i)& 1 & 0 \\ -2& 3 - (2 + i) & 0 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{cc|c} -1 - i& 1 & 0 \\ -2& 1 - i & 0 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -1 - i& 1 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[NEWLINE][TAB]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -2 - 2i& 2 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ \times\!\!= 2\\[NEWLINE][TAB]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -2i& 1 + i & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= -\mathbf{r_1}\\[NEWLINE][TAB]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= -i\mathbf{r_1}\\[NEWLINE][TAB]-2v_1 + (1 - i)v_2 &= 0\\[NEWLINE][TAB]v_1 &= \frac{1 - i}{2}v_2.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc|c} 1 - (2 + i)& 1 & 0 \\ -2& 3 - (2 + i) & 0 \end{array}\right] &\\[4px]\left[\begin{array}{cc|c} -1 - i& 1 & 0 \\ -2& 1 - i & 0 \end{array}\right] &\\[4px]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -1 - i& 1 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[4px]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -2 - 2i& 2 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ \times\!\!= 2\\[4px]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ -2i& 1 + i & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= -\mathbf{r_1}\\[4px]\left[\begin{array}{cc|c} -2& 1 - i & 0 \\ 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= -i\mathbf{r_1}\\[4px]-2v_1 + (1 - i)v_2 &= 0\\[4px]v_1 &= \frac{1 - i}{2}v_2.\end{align*}$$</span></p><p class="body-text">With <span class="tex-holder inline-math" data-source-tex="v_2 = 2">$v_2 = 2$,</span> we have</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Although row reducing a complex matrix is a little more work, the bright side is that we also know the eigenvector corresponding to <span class="tex-holder inline-math" data-source-tex="\lambda = 2 - i">$\lambda = 2 - i$:</span> it&#x2019;s the conjugate of the vector <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> we found. So the eigenvalues and eigenvectors are</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\lambda = 2 + i: & \quad \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right]\\[NEWLINE][TAB]\lambda = 2 - i: & \quad \left[\begin{array}{c} 1 + i \\ 2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\lambda = 2 + i: & \quad \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right]\\[4px]\lambda = 2 - i: & \quad \left[\begin{array}{c} 1 + i \\ 2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">However, we won&#x2019;t actually need the other eigenvector &mdash; just like with complex roots of the characteristic equation, all the data we need is contained in the real and imaginary parts of a single eigenvalue and eigenvector. Let&#x2019;s write out the part of the solution that comes from <span class="tex-holder inline-math" data-source-tex="\lambda = 2 + i">$\lambda = 2 + i$:</span></p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{p} &= e^{(2 + i)t} \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right]\\[NEWLINE][TAB]&= e^{2t}(\cos(t) + i\sin(t)) \left( \left[\begin{array}{c} 1 \\ 2 \end{array}\right] + i\left[\begin{array}{c} - 1 \\ 0 \end{array}\right] \right).[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{p} &= e^{(2 + i)t} \left[\begin{array}{c} 1 - i \\ 2 \end{array}\right]\\[4px]&= e^{2t}(\cos(t) + i\sin(t)) \left( \left[\begin{array}{c} 1 \\ 2 \end{array}\right] + i\left[\begin{array}{c} - 1 \\ 0 \end{array}\right] \right).\end{align*}$$</span></p><p class="body-text">The number of terms can seem a little off-putting, but we actually want to foil this out &mdash; that way, we can completely separate the real and imaginary parts.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{p} &= e^{2t}\cos(t)\left[\begin{array}{c} 1 \\ 2 \end{array}\right] + ie^{2t}\cos(t)\left[\begin{array}{c} - 1 \\ 0 \end{array}\right] + ie^{2t}\sin(t)\left[\begin{array}{c} 1 \\ 2 \end{array}\right] + i^2e^{2t}\sin(t)\left[\begin{array}{c} - 1 \\ 0 \end{array}\right]\\[NEWLINE][TAB]&= e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] + ie^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{p} &= e^{2t}\cos(t)\left[\begin{array}{c} 1 \\ 2 \end{array}\right] + ie^{2t}\cos(t)\left[\begin{array}{c} - 1 \\ 0 \end{array}\right] + ie^{2t}\sin(t)\left[\begin{array}{c} 1 \\ 2 \end{array}\right] + i^2e^{2t}\sin(t)\left[\begin{array}{c} - 1 \\ 0 \end{array}\right]\\[4px]&= e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] + ie^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right].\end{align*}$$</span></p><p class="body-text">The real and imaginary parts here are fundamental solutions: they&#x2019;re both solutions and linearly independent. Therefore, our general solution is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{p} = c_1 e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] + c_2 e^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{p} = c_1 e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] + c_2 e^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right].\end{align*}$$</span></p><p class="body-text">Now for the rest of the bookkeeping. The initial condition is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{p}(0) &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right]\\[NEWLINE][TAB]c_1 e^{0} \left[\begin{array}{c} \cos(0) + \sin(0) \\ 2\cos(0) \end{array}\right] + c_2 e^{0}\left[\begin{array}{c} \sin(0) - \cos(0) \\ 2\sin(0) \end{array}\right] &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right]\\[NEWLINE][TAB]c_1 \left[\begin{array}{c} 1 \\ 2 \end{array}\right] + c_2 \left[\begin{array}{c} -1 \\ 0 \end{array}\right] &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{p}(0) &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right]\\[4px]c_1 e^{0} \left[\begin{array}{c} \cos(0) + \sin(0) \\ 2\cos(0) \end{array}\right] + c_2 e^{0}\left[\begin{array}{c} \sin(0) - \cos(0) \\ 2\sin(0) \end{array}\right] &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right]\\[4px]c_1 \left[\begin{array}{c} 1 \\ 2 \end{array}\right] + c_2 \left[\begin{array}{c} -1 \\ 0 \end{array}\right] &= \left[\begin{array}{c} 100 \\ 100 \end{array}\right].\end{align*}$$</span></p><p class="body-text">We can form a matrix and row reduce to solve for <span class="tex-holder inline-math" data-source-tex="c_1">$c_1$</span> and <span class="tex-holder inline-math" data-source-tex="c_2">$c_2$,</span> but here it&#x2019;s easier to just solve it manually: the bottom equation reads <span class="tex-holder inline-math" data-source-tex="2c_1 = 100">$2c_1 = 100$,</span> so <span class="tex-holder inline-math" data-source-tex="c_1 = 50">$c_1 = 50$,</span> and then <span class="tex-holder inline-math" data-source-tex="c_1 - c_2 = 100">$c_1 - c_2 = 100$,</span> so <span class="tex-holder inline-math" data-source-tex="c_2 = -50">$c_2 = -50$.</span> Our particular solution is therefore</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{p} &= 50 e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] - 50 e^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right]\\[NEWLINE][TAB]&= 100 e^{2t} \left[\begin{array}{c} \cos(t) \\ \cos(t) - \sin(t) \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{p} &= 50 e^{2t} \left[\begin{array}{c} \cos(t) + \sin(t) \\ 2\cos(t) \end{array}\right] - 50 e^{2t}\left[\begin{array}{c} \sin(t) - \cos(t) \\ 2\sin(t) \end{array}\right]\\[4px]&= 100 e^{2t} \left[\begin{array}{c} \cos(t) \\ \cos(t) - \sin(t) \end{array}\right].\end{align*}$$</span></p><p class="body-text">This system is exhibiting unbounded exponential growth, so it&#x2019;s probably not the complete story: maybe an ecosystem consisting only of these two species would be mutually beneficial to an extreme degree, but factors like other predators and the carrying capacity of the ecosystem play roles unaccounted-for here.</p><p class="body-text">Sketching a direction field, we can see a distinct spiral shape. When a <span class="tex-holder inline-math" data-source-tex="2 \times 2">$2 \times 2$</span> system of DEs has complex conjugate eigenvalues, we see either a spiral into or out from the origin, depending on whether the sign of the real part of the eigenvalues is positive or negative.</p><div class="desmos-border"><div id="vectorField" class="desmos-container"></div></div><div class="desmos-border canvas-container"><canvas id="vector-field-canvas" class="output-canvas"></canvas></div></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: complex eigenvalues</div><p class="body-text">Chemical solutions <span class="tex-holder inline-math" data-source-tex="A">$A$</span> and <span class="tex-holder inline-math" data-source-tex="B">$B$</span> are mixed together and react. Large amounts of solution <span class="tex-holder inline-math" data-source-tex="A">$A$</span> are rapidly converted to small amounts of solution <span class="tex-holder inline-math" data-source-tex="B">$B$,</span> and both <span class="tex-holder inline-math" data-source-tex="A">$A$</span> and <span class="tex-holder inline-math" data-source-tex="B">$B$</span> decay into an inert solution at a moderate rate. Specifically, if the masses of solutions <span class="tex-holder inline-math" data-source-tex="A">$A$</span> and <span class="tex-holder inline-math" data-source-tex="B">$B$</span> are given by <span class="tex-holder inline-math" data-source-tex="m_1">$m_1$</span> and <span class="tex-holder inline-math" data-source-tex="m_2">$m_2$</span> in grams after <span class="tex-holder inline-math" data-source-tex="t">$t$</span> seconds, then</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]m_1' &= -m_1 - 9m_2\\[NEWLINE][TAB]m_2' &= m_1 - m_2.[NEWLINE]\end{align*}">$$\begin{align*}m_1' &= -m_1 - 9m_2\\[4px]m_2' &= m_1 - m_2.\end{align*}$$</span></p><p class="body-text">At time <span class="tex-holder inline-math" data-source-tex="t = 0">$t = 0$,</span> <span class="tex-holder inline-math" data-source-tex="10\,g">$10\,g$</span> of both solutions are mixed together. How much of each remains after 10 seconds? Sketch a direction field.</p></div></section><h2 class="section-text">Repeated Eigenvalues</h2><section><p class="body-text">In individual <span class="tex-holder inline-math" data-source-tex="n">$n$th-order</span> DEs, repeated roots of the characteristic equation were always a problem: we read off fundamental solutions directly from those roots. When eigenvalues of a matrix are repeated, though, the corresponding eigenvalues don&#x2019;t necessarily repeat. For example, let</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{A} = \left[\begin{array}{cc} 0& -1 \\ 1& -2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{A} = \left[\begin{array}{cc} 0& -1 \\ 1& -2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Solving for the eigenvalues gives us <span class="tex-holder inline-math" data-source-tex="\lambda^2 + 2\lambda + 1 = 0">$\lambda^2 + 2\lambda + 1 = 0$,</span> so <span class="tex-holder inline-math" data-source-tex="\lambda = -1">$\lambda = -1$.</span> When we subtract it from the diagonal, we find</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc|c} 1& -1 & 0 \\ 1& -1 & 0 \end{array}\right],[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc|c} 1& -1 & 0 \\ 1& -1 & 0 \end{array}\right],\end{align*}$$</span></p><p class="body-text">so <span class="tex-holder inline-math" data-source-tex="v_1 = v_2">$v_1 = v_2$.</span> Taking <span class="tex-holder inline-math" data-source-tex="v_2 = 1">$v_2 = 1$,</span> our single eigenvector is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} 1 \\ 1 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} 1 \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">On the other hand,</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]B = \left[\begin{array}{cc} -1& 0 \\ 0& -1 \end{array}\right][NEWLINE]\end{align*}">$$\begin{align*}B = \left[\begin{array}{cc} -1& 0 \\ 0& -1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">has a repeated eigenvalue of <span class="tex-holder inline-math" data-source-tex="\lambda = -1">$\lambda = -1$,</span> but when we solve for the eigenvectors, we get a matrix of all zeros, so there are two free parameters. When we can choose more than one entry of <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$,</span> a good strategy is to choose one of them to be one and the rest to be zero, and repeat for all of the entries. Taking <span class="tex-holder inline-math" data-source-tex="v_1 = 1">$v_1 = 1$</span> and <span class="tex-holder inline-math" data-source-tex="v_2 = 0">$v_2 = 0$,</span> then <span class="tex-holder inline-math" data-source-tex="v_1 = 0">$v_1 = 0$</span> and <span class="tex-holder inline-math" data-source-tex="v_2 = 1">$v_2 = 1$,</span> we get</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v}_1 = \left[\begin{array}{c} 1 \\ 0 \end{array}\right], \qquad \mathbf{v}_2 = \left[\begin{array}{c} 0 \\ 1 \end{array}\right]. [NEWLINE]$$">$$\begin{align*}\mathbf{v}_1 = \left[\begin{array}{c} 1 \\ 0 \end{array}\right], \qquad \mathbf{v}_2 = \left[\begin{array}{c} 0 \\ 1 \end{array}\right]. \end{align*}$$</span></p><p class="body-text">So our metaphor of eigenvalues working like roots of the characteristic equation isn&#x2019;t quite one-to-one: repeated eigenvalues aren&#x2019;t always a problem. When there are still <span class="tex-holder inline-math" data-source-tex="n">$n$</span> different eigen<em>vectors</em>, we don&#x2019;t need to do anything, but when there actually are fewer, we&#x2019;ll need to work to get more solutions. The technical details are similar to reduction of order, but they result in a rather different solution. To get started, we&#x2019;ll need a slight generalization of the notion of an eigenvector. Fittingly enough, these are called</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: generalized eigenvector</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> be an <span class="tex-holder inline-math" data-source-tex="n \times n">$n \times n$</span> matrix and let <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> be an eigenvector with eigenvalue <span class="tex-holder inline-math" data-source-tex="\lambda">$\lambda$.</span> A <strong>generalized eigenvector</strong> of <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> is a vector <span class="tex-holder inline-math" data-source-tex="\mathbf{w}">$\mathbf{w}$</span> with</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB](\mathbf{A} - \lambda\mathbf{I})\mathbf{w} = \mathbf{v}.[NEWLINE]$$">$$\begin{align*}(\mathbf{A} - \lambda\mathbf{I})\mathbf{w} = \mathbf{v}.\end{align*}$$</span></p><p class="body-text">We can also find the generalized eigenvectors of <span class="tex-holder inline-math" data-source-tex="\mathbf{w}">$\mathbf{w}$,</span> and so on. There are always <span class="tex-holder inline-math" data-source-tex="n">$n$</span> linearly independent generalized eigenvectors of an <span class="tex-holder inline-math" data-source-tex="n \times n">$n \times n$</span> matrix, and the number of generalized eigenvectors corresponding to a single eigenvalue <span class="tex-holder inline-math" data-source-tex="\lambda">$\lambda$</span> is the number of times it appears as a root in the characteristic polynomial.</p></div><p class="body-text">As an opening example, let&#x2019;s return to our previous matrix with a repeated eigenvector:</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{A} = \left[\begin{array}{cc} 0& -1 \\ 1& -2 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{A} = \left[\begin{array}{cc} 0& -1 \\ 1& -2 \end{array}\right].\end{align*}$$</span></p><p class="body-text">We found that the single eigenvector was</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} 11 \\ 1 \end{array}\right],[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} 11 \\ 1 \end{array}\right],\end{align*}$$</span></p><p class="body-text">and its eigenvalue was <span class="tex-holder inline-math" data-source-tex="\lambda = -1">$\lambda = -1$.</span> To find its generalized eigenvectors, we solve</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB](\mathbf{A} - \lambda\mathbf{I})\mathbf{w} = \mathbf{v},[NEWLINE]$$">$$\begin{align*}(\mathbf{A} - \lambda\mathbf{I})\mathbf{w} = \mathbf{v},\end{align*}$$</span></p><p class="body-text">which means row reducing the matrix</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc|c} 1& -1 & 1 \\ 1& -1 & 1 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc|c} 1& -1 & 1 \\ 1& -1 & 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">The bottom row reduces to all zeros, so we just have <span class="tex-holder inline-math" data-source-tex="w_1 - w_2 = 1">$w_1 - w_2 = 1$.</span> Therefore, <span class="tex-holder inline-math" data-source-tex="w_1 = w_2 + 1">$w_1 = w_2 + 1$,</span> so if we take <span class="tex-holder inline-math" data-source-tex="w_2 = 0">$w_2 = 0$,</span> then our generalized eigenvector is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{w} = \left[\begin{array}{c} 1 \\ 0 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{w} = \left[\begin{array}{c} 1 \\ 0 \end{array}\right].\end{align*}$$</span></p><p class="body-text">So even though <span class="tex-holder inline-math" data-source-tex="(\mathbf{A} - (-1)\mathbf{I})\mathbf{w} \neq \mathbf{0}">$(\mathbf{A} - (-1)\mathbf{I})\mathbf{w} \neq \mathbf{0}$,</span> it is the case that <span class="tex-holder inline-math" data-source-tex="(\mathbf{A} - (-1)\mathbf{I})^2\mathbf{w} = \mathbf{0}">$(\mathbf{A} - (-1)\mathbf{I})^2\mathbf{w} = \mathbf{0}$.</span> Continuing to try to generalize <span class="tex-holder inline-math" data-source-tex="\mathbf{w}">$\mathbf{w}$</span> results in no solutions at all, and so we&#x2019;ve exhausted the list.</p><p class="body-text">Without a use for them, it doesn&#x2019;t make much sense to find generalized eigenvectors, but you might already see where we&#x2019;re going with this: they&#x2019;re exactly the tool we need to find missing fundamental solutions to a system of DEs.</p><div class="notes-thm notes-environment"><div class="notes-thm-title notes-title">Theorem: solving a system with repeated eigenvectors</div><p class="body-text">Suppose the matrix <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$</span> has an eigenvector <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> that is repeated once &mdash; i.e. the eigenvalue <span class="tex-holder inline-math" data-source-tex="\lambda">$\lambda$</span> appears as a root of the characteristic polynomial twice but there is only one eigenvector <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> corresponding to it. Then the second fundamental solution to <span class="tex-holder inline-math" data-source-tex="\mathbf{x}' = \mathbf{Ax}">$\mathbf{x}' = \mathbf{Ax}$</span> with eigenvalue <span class="tex-holder inline-math" data-source-tex="\lambda">$\lambda$</span> is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]te^{\lambda t} \mathbf{v} + e^{\lambda t}\mathbf{w},[NEWLINE]$$">$$\begin{align*}te^{\lambda t} \mathbf{v} + e^{\lambda t}\mathbf{w},\end{align*}$$</span></p><p class="body-text">where <span class="tex-holder inline-math" data-source-tex="\mathbf{w}">$\mathbf{w}$</span> is the generalized eigenvector of <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$.</span></p></div><p class="body-text">This theorem tells us how to handle an eigenvector repeated once, but no more than that: if it&#x2019;s repeated three or more times, there is a similar form involving increasing powers of <span class="tex-holder inline-math" data-source-tex="t">$t$,</span> factorials in denominators, and chains of generalized eigenvalues. This actually isn&#x2019;t all that complicated, but the examples required to see it in action are <span class="tex-holder inline-math" data-source-tex="4 \times 4">$4 \times 4$</span> at minimum, and so we&#x2019;ll be leaving them out of the course.</p><p class="body-text">When an eigenvalue <span class="tex-holder inline-math" data-source-tex="\lambda">$\lambda$</span> appears twice in the characteristic polynomial, but row reducing <span class="tex-holder inline-math" data-source-tex="\mathbf{A} - \lambda \mathbf{I}">$\mathbf{A} - \lambda \mathbf{I}$</span> only has one free parameter, then we find an eigenvector <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$</span> and row reduce <span class="tex-holder inline-math" data-source-tex="\mathbf{A} - \lambda \mathbf{I}">$\mathbf{A} - \lambda \mathbf{I}$</span> again &mdash; but this time we augment it with <span class="tex-holder inline-math" data-source-tex="\mathbf{v}">$\mathbf{v}$,</span> not <span class="tex-holder inline-math" data-source-tex="\mathbf{0}">$\mathbf{0}$.</span> We&#x2019;ll find a generalized eigenvector <span class="tex-holder inline-math" data-source-tex="\mathbf{w}">$\mathbf{w}$,</span> and then we can plug that into the previous theorem. Let&#x2019;s see this in action:</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: a repeated eigenvector</div><p class="body-text">The heating in University hall is horribly broken (still). The basement, first floor, and second floor are heated and cooled at varying degrees, and since the floors are adjacent, the temperature on one floor affects the temperature on others. Specifically, if the temperatures are <span class="tex-holder inline-math" data-source-tex="x_1">$x_1$,</span> <span class="tex-holder inline-math" data-source-tex="x_2">$x_2$,</span> and <span class="tex-holder inline-math" data-source-tex="x_3">$x_3$,</span> then their rates of change are given by</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]x_1' &= 6x_1 - 2x_2 + 3x_3\\[NEWLINE][TAB]x_2' &= -7x_1 + 7x_2 - 7x_3\\[NEWLINE][TAB]x_3' &= -10x_1 + 6x_2 - 7x_3.[NEWLINE]\end{align*}">$$\begin{align*}x_1' &= 6x_1 - 2x_2 + 3x_3\\[4px]x_2' &= -7x_1 + 7x_2 - 7x_3\\[4px]x_3' &= -10x_1 + 6x_2 - 7x_3.\end{align*}$$</span></p><p class="body-text">Find the general solution for <span class="tex-holder inline-math" data-source-tex="\mathbf{x}">$\mathbf{x}$.</span></p><p class="body-text">We&#x2019;ll get started by turning the system into a matrix as usual:</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{x}' = \left[\begin{array}{ccc} 6& -2& 3 \\ -7& 7& -7 \\ -10& 6& -7 \end{array}\right]\mathbf{x}.[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{x}' = \left[\begin{array}{ccc} 6& -2& 3 \\ -7& 7& -7 \\ -10& 6& -7 \end{array}\right]\mathbf{x}.\end{align*}$$</span></p><p class="body-text">Calling that matrix <span class="tex-holder inline-math" data-source-tex="\mathbf{A}">$\mathbf{A}$,</span> let&#x2019;s find its eigenvalues.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\det \left[\begin{array}{ccc} 6 - \lambda& -2& 3 \\ -7& 7 - \lambda& -7 \\ -10& 6& -7 - \lambda \end{array}\right] &= 0\\[NEWLINE][TAB](6 - \lambda)((7 - \lambda)(-7 - \lambda) + 42) + 2((-7)(-7 - \lambda) - 70) + 3(-42 + 10(7 - \lambda)) &= 0\\[NEWLINE][TAB](6 - \lambda)(-7 + \lambda^2) + 2(-21 + 7\lambda) + 3(28 - 10\lambda) &= 0\\[NEWLINE][TAB]-42 + 7\lambda + 6\lambda^2 - \lambda^3 - 42 + 14\lambda + 84 - 30\lambda &= 0\\[NEWLINE][TAB]-\lambda^3 + 6\lambda^2 - 9\lambda &= 0\\[NEWLINE][TAB]-\lambda(\lambda - 3)^2 &= 0\\[NEWLINE][TAB]\lambda = 0, \quad \lambda = 3, \quad \lambda &= 3[NEWLINE]\end{align*}">$$\begin{align*}\det \left[\begin{array}{ccc} 6 - \lambda& -2& 3 \\ -7& 7 - \lambda& -7 \\ -10& 6& -7 - \lambda \end{array}\right] &= 0\\[4px](6 - \lambda)((7 - \lambda)(-7 - \lambda) + 42) + 2((-7)(-7 - \lambda) - 70) + 3(-42 + 10(7 - \lambda)) &= 0\\[4px](6 - \lambda)(-7 + \lambda^2) + 2(-21 + 7\lambda) + 3(28 - 10\lambda) &= 0\\[4px]-42 + 7\lambda + 6\lambda^2 - \lambda^3 - 42 + 14\lambda + 84 - 30\lambda &= 0\\[4px]-\lambda^3 + 6\lambda^2 - 9\lambda &= 0\\[4px]-\lambda(\lambda - 3)^2 &= 0\\[4px]\lambda = 0, \quad \lambda = 3, \quad \lambda &= 3\end{align*}$$</span></p><p class="body-text">In total, we expect one eigenvector with eigenvalue <span class="tex-holder inline-math" data-source-tex="0">$0$</span> and two with eigenvalue <span class="tex-holder inline-math" data-source-tex="3">$3$.</span> Let&#x2019;s see how that pans out! With <span class="tex-holder inline-math" data-source-tex="\lambda = 0">$\lambda = 0$,</span> we have</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 6& -2& 3 & 0 \\ -7& 7& -7 & 0 \\ -10& 6& -7 & 0 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 6& -2& 3 & 0 \\ -1& 5& -4 & 0 \\ -10& 6& -7 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= \mathbf{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 5& -4 & 0 \\ 6& -2& 3 & 0 \\ -10& 6& -7 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 5& -4 & 0 \\ 0& 28& -21 & 0 \\ 0& -44& 33 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 6 \mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10 \mathbf{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& -5& 4 & 0 \\ 0& 4& -3 & 0 \\ 0& 4& -3 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= \frac{1}{7} \\ \mathbf{r_3} \ \times\!\!= -\frac{1}{11} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& -5& 4 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 6& -2& 3 & 0 \\ -7& 7& -7 & 0 \\ -10& 6& -7 & 0 \end{array}\right] &\\[4px]\left[\begin{array}{ccc|c} 6& -2& 3 & 0 \\ -1& 5& -4 & 0 \\ -10& 6& -7 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= \mathbf{r_1}\\[4px]\left[\begin{array}{ccc|c} -1& 5& -4 & 0 \\ 6& -2& 3 & 0 \\ -10& 6& -7 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[4px]\left[\begin{array}{ccc|c} -1& 5& -4 & 0 \\ 0& 28& -21 & 0 \\ 0& -44& 33 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 6 \mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10 \mathbf{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& -5& 4 & 0 \\ 0& 4& -3 & 0 \\ 0& 4& -3 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= \frac{1}{7} \\ \mathbf{r_3} \ \times\!\!= -\frac{1}{11} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& -5& 4 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}\end{align*}$$</span></p><p class="body-text">In the interest of avoiding fractions, let&#x2019;s multiply the rows to get a common multiple rather than dividing them.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 4& -20& 16 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_1} \ \times\!\!= 4\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 4& 0& 1 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_1} \ +\!\!= 5\mathbf{r_2}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 4& -20& 16 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_1} \ \times\!\!= 4\\[4px]\left[\begin{array}{ccc|c} 4& 0& 1 & 0 \\ 0& 4& -3 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_1} \ +\!\!= 5\mathbf{r_2}\end{align*}$$</span></p><p class="body-text">In total, <span class="tex-holder inline-math" data-source-tex="4v_1 = -v_3">$4v_1 = -v_3$</span> and <span class="tex-holder inline-math" data-source-tex="4v_2 = 3v_3">$4v_2 = 3v_3$.</span> Choosing <span class="tex-holder inline-math" data-source-tex="v_3 = 4">$v_3 = 4$</span> (again in the interest of minimizing fractions) results in <span class="tex-holder inline-math" data-source-tex="v_1 = -1">$v_1 = -1$</span> and <span class="tex-holder inline-math" data-source-tex="v_2 = 3">$v_2 = 3$,</span> so our first eigenvector is</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Only one eigenvector there, but that&#x2019;s what we were expecting: since <span class="tex-holder inline-math" data-source-tex="\lambda = 0">$\lambda = 0$</span> only appears once in the characteristic polynomial, it can have at most one eigenvector. Now let&#x2019;s take a look at <span class="tex-holder inline-math" data-source-tex="\lambda = 3">$\lambda = 3$:</span></p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& -2& 3 & 0 \\ -7& 4& -7 & 0 \\ -10& 6& -10 & 0 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& -2& 3 & 0 \\ -1& 0& -1 & 0 \\ -10& 6& -10 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= 2\mathbf{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 0& -1 & 0 \\ 3& -2& 3 & 0 \\ -10& 6& -10 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 0& -1 & 0 \\ 0& -2& 0 & 0 \\ 0& 6& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 3\mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10\mathbf{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 1& 0 & 0 \\ 0& 1& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= -\frac{1}{2} \\ \mathbf{r_3} \ \times\!\!= \frac{1}{6} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 1& 0 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 3& -2& 3 & 0 \\ -7& 4& -7 & 0 \\ -10& 6& -10 & 0 \end{array}\right] &\\[4px]\left[\begin{array}{ccc|c} 3& -2& 3 & 0 \\ -1& 0& -1 & 0 \\ -10& 6& -10 & 0 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= 2\mathbf{r_1}\\[4px]\left[\begin{array}{ccc|c} -1& 0& -1 & 0 \\ 3& -2& 3 & 0 \\ -10& 6& -10 & 0 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[4px]\left[\begin{array}{ccc|c} -1& 0& -1 & 0 \\ 0& -2& 0 & 0 \\ 0& 6& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 3\mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10\mathbf{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 1& 0 & 0 \\ 0& 1& 0 & 0 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= -\frac{1}{2} \\ \mathbf{r_3} \ \times\!\!= \frac{1}{6} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 1 & 0 \\ 0& 1& 0 & 0 \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}\end{align*}$$</span></p><p class="body-text">As equations, <span class="tex-holder inline-math" data-source-tex="v_1 = -v_3">$v_1 = -v_3$</span> and <span class="tex-holder inline-math" data-source-tex="v_2 = 0">$v_2 = 0$.</span> There&#x2019;s only one free parameter here, so if we choose <span class="tex-holder inline-math" data-source-tex="v_3 = 1">$v_3 = 1$,</span> we get an eigenvector of</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">But we&#x2019;re supposed to have two eigenvectors corresponding to <span class="tex-holder inline-math" data-source-tex="\lambda = 3">$\lambda = 3$!</span> That means there should be a generalized eigenvector hiding here: to find it, we take the same matrix we just row reduced, but this time, we augment it with this vector. Thankfully, all the steps are the same, so we just need to keep track of the right side.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& -2& 3 & -1 \\ -7& 4& -7 & 0 \\ -10& 6& -10 & 1 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& -2& 3 & -1 \\ -1& 0& -1 & -2 \\ -10& 6& -10 & 1 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= 2\mathbf{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 0& -1 & -2 \\ 3& -2& 3 & -1 \\ -10& 6& -10 & 1 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} -1& 0& -1 & -2 \\ 0& -2& 0 & -7 \\ 0& 6& 0 & 21 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 3\mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10\mathbf{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 1 & 2 \\ 0& 1& 0 & \frac{7}{2} \\ 0& 1& 0 & \frac{7}{2} \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= -\frac{1}{2} \\ \mathbf{r_3} \ \times\!\!= \frac{1}{6} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 1 & 2 \\ 0& 1& 0 & \frac{7}{2} \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 3& -2& 3 & -1 \\ -7& 4& -7 & 0 \\ -10& 6& -10 & 1 \end{array}\right] &\\[4px]\left[\begin{array}{ccc|c} 3& -2& 3 & -1 \\ -1& 0& -1 & -2 \\ -10& 6& -10 & 1 \end{array}\right] & \qquad \mathbf{r_2} \ +\!\!= 2\mathbf{r_1}\\[4px]\left[\begin{array}{ccc|c} -1& 0& -1 & -2 \\ 3& -2& 3 & -1 \\ -10& 6& -10 & 1 \end{array}\right] & \qquad \operatorname{swap} \mathbf{r_1}, \mathbf{r_2}\\[4px]\left[\begin{array}{ccc|c} -1& 0& -1 & -2 \\ 0& -2& 0 & -7 \\ 0& 6& 0 & 21 \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_2} \ +\!\!= 3\mathbf{r_1} \\ \mathbf{r_3} \ +\!\!= -10\mathbf{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 1 & 2 \\ 0& 1& 0 & \frac{7}{2} \\ 0& 1& 0 & \frac{7}{2} \end{array}\right] & \qquad \begin{array}{l} \mathbf{r_1} \ \times\!\!= -1 \\ \mathbf{r_2} \ \times\!\!= -\frac{1}{2} \\ \mathbf{r_3} \ \times\!\!= \frac{1}{6} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 1 & 2 \\ 0& 1& 0 & \frac{7}{2} \\ 0& 0& 0 & 0 \end{array}\right] & \qquad \mathbf{r_3} \ +\!\!= -\mathbf{r_2}\end{align*}$$</span></p><p class="body-text">This time, <span class="tex-holder inline-math" data-source-tex="v_1 = 2 - v_3">$v_1 = 2 - v_3$</span> and <span class="tex-holder inline-math" data-source-tex="v_2 = \frac{7}{2}">$v_2 = \frac{7}{2}$.</span> With <span class="tex-holder inline-math" data-source-tex="v_3 = 1">$v_3 = 1$,</span> we get</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\mathbf{v} = \left[\begin{array}{c} 1 \\ \frac{7}{2} \\ 1 \end{array}\right].[NEWLINE]$$">$$\begin{align*}\mathbf{v} = \left[\begin{array}{c} 1 \\ \frac{7}{2} \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Now we&#x2019;re ready to go. The first two fundamental solutions work as normal, but the third is constructed using the previous theorem.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\mathbf{x} &= c_1e^{0t} \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right] + c_2e^{3t} \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + c_3e^{3t} \left( t\left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + \left[\begin{array}{c} 1 \\ \frac{7}{2} \\ 1 \end{array}\right] \right)\\[NEWLINE][TAB]&= c_1 \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right] + c_2e^{3t} \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + c_3e^{3t} \left[\begin{array}{c} -t + 1 \\ \frac{7}{2} \\ t + 1 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}\mathbf{x} &= c_1e^{0t} \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right] + c_2e^{3t} \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + c_3e^{3t} \left( t\left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + \left[\begin{array}{c} 1 \\ \frac{7}{2} \\ 1 \end{array}\right] \right)\\[4px]&= c_1 \left[\begin{array}{c} -1 \\ 3 \\ 4 \end{array}\right] + c_2e^{3t} \left[\begin{array}{c} -1 \\ 0 \\ 1 \end{array}\right] + c_3e^{3t} \left[\begin{array}{c} -t + 1 \\ \frac{7}{2} \\ t + 1 \end{array}\right].\end{align*}$$</span></p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: a repeated eigenvector</div><p class="body-text">Solve the system of DEs given by</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]x' &= 5x + y\\[NEWLINE][TAB]y' &= -x + 3y.[NEWLINE]\end{align*}">$$\begin{align*}x' &= 5x + y\\[4px]y' &= -x + 3y.\end{align*}$$</span></p></div><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div></section></main>