<header><div id="logo"><a href="/home/" tabindex="-1"><img src="/graphics/general-icons/logo.webp" alt="Logo" tabindex="1"></img></a></div><div style="height: 20px"></div><h1 class="heading-text">Section 8: Bases and Dimension</h1></header><main><section><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div><p class="body-text">So far, generalizing all of our results to different vector spaces hasn&#x2019;t been too terrible. The objects in our new spaces differ quite a bit from those in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> &mdash; the only vector space we studied in the first six sections &mdash; but the tools we&#x2019;ve used to study them are nearly identical. Vectors can be added and multiplied by scalars, and linear transformations are defined in exactly the same way. However, so much of what we&#x2019;ve learned relies on <em>matrices</em>, and at the moment, we just don&#x2019;t have those. To recap, the reason we can express a linear transformation <span class="tex-holder inline-math" data-source-tex="T : \mathbb{R}^n \to \mathbb{R}^m">$T : \mathbb{R}^n \to \mathbb{R}^m$</span> as multiplication by an <span class="tex-holder inline-math" data-source-tex="m \times n">$m \times n$</span> matrix <span class="tex-holder inline-math" data-source-tex="A">$A$</span> is because any vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$</span> can be expressed as a linear combination of the <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$:</span></p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = \left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right] = c_1\vec{e_1} + c_2\vec{e_2} + \cdots + c_n\vec{e_n}.[NEWLINE]$$">$$\begin{align*}\vec{v} = \left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right] = c_1\vec{e_1} + c_2\vec{e_2} + \cdots + c_n\vec{e_n}.\end{align*}$$</span></p><p class="body-text">Then applying <span class="tex-holder inline-math" data-source-tex="T">$T$</span> to both sides results in</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T(\vec{v}) = T\left( \left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right]\right) = c_1T(\vec{e_1}) + c_2T(\vec{e_2}) + \cdots + c_nT(\vec{e_n}),[NEWLINE]$$">$$\begin{align*}T(\vec{v}) = T\left( \left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right]\right) = c_1T(\vec{e_1}) + c_2T(\vec{e_2}) + \cdots + c_nT(\vec{e_n}),\end{align*}$$</span></p><p class="body-text">and that linear combination can be expressed as the matrix-vector product</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T(\vec{v}) = \left[\begin{array}{cccc} \mid& \mid& & \mid \\ T(\vec{e_1})& T(\vec{e_2})& \cdots& T(\vec{e_n}) \\ \mid& \mid& & \mid \end{array}\right]\left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}T(\vec{v}) = \left[\begin{array}{cccc} \mid& \mid& & \mid \\ T(\vec{e_1})& T(\vec{e_2})& \cdots& T(\vec{e_n}) \\ \mid& \mid& & \mid \end{array}\right]\left[\begin{array}{c} c_1 \\ c_2 \\ \vdots \\ c_n \end{array}\right].\end{align*}$$</span></p><p class="body-text">So how can we bring this idea to a general vector space <span class="tex-holder inline-math" data-source-tex="V">$V$?</span> If we could find a collection of fundamental vectors like <span class="tex-holder inline-math" data-source-tex="\vec{e_1}, ..., \vec{e_n}">$\vec{e_1}, ..., \vec{e_n}$</span> so that we could express any <span class="tex-holder inline-math" data-source-tex="\vec{v} \in V">$\vec{v} \in V$</span> as a linear combination of them &mdash; ideally in a unique way &mdash; then we&#x2019;d be able to reap the same benefits of matrices: by computing a linear transformation&#x2019;s effect on just those fundamental vectors, we&#x2019;d then be able to find its effect on any vector at all.</p><p class="body-text">What conditions will we need to make that a reality? If we want a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V">$\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V$</span> so that any <span class="tex-holder inline-math" data-source-tex="\vec{v} \in V">$\vec{v} \in V$</span> is expressible as a unique linear combination of the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$,</span> then an immediate first requirement is that the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> need to span <span class="tex-holder inline-math" data-source-tex="V">$V$</span> &mdash; otherwise, some vectors wouldn&#x2019;t be expressible as a linear combination of them at all, let alone a unique one. To guarantee the uniqueness condition, a rather technical argument can show that we need the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> to be linearly independent (it&#x2019;s very similar to the one that shows a linear transformation from <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^m">$\mathbb{R}^m$</span> is one-to-one if it sends only <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$</span> to <span class="tex-holder inline-math" data-source-tex="\vec{0}">$\vec{0}$).</span> When we say linearly independent and spanning, we mean exactly the same thing as we did in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> but let&#x2019;s take the time to write down the formal definitions in a general vector space <span class="tex-holder inline-math" data-source-tex="V">$V$,</span> and then name the collection of vectors whose linear combinations express all others uniquely.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: linear independence and span</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="V">$V$</span> be a vector space. A collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V">$\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V$</span> is <strong> linearly independent</strong> if the only linear combination</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{0}[NEWLINE]$$">$$\begin{align*}c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{0}\end{align*}$$</span></p><p class="body-text">is when <span class="tex-holder inline-math" data-source-tex="c_1 = c_2 = \cdots = c_n = 0">$c_1 = c_2 = \cdots = c_n = 0$.</span> The <strong>span</strong> of the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> is the set of all their possible linear combinations, and we say the collection <strong>spans</strong> <span class="tex-holder inline-math" data-source-tex="V">$V$</span> if</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\operatorname{span} \{ \vec{v_1}, \vec{v_2}, ..., \vec{v_n} \} = V.[NEWLINE]$$">$$\begin{align*}\operatorname{span} \{ \vec{v_1}, \vec{v_2}, ..., \vec{v_n} \} = V.\end{align*}$$</span></p></div><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: basis</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="V">$V$</span> be a vector space. A <strong>basis</strong> for <span class="tex-holder inline-math" data-source-tex="V">$V$</span> is a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V">$\vec{v_1}, \vec{v_2}, ..., \vec{v_n} \in V$</span> that is linearly independent and spans <span class="tex-holder inline-math" data-source-tex="V">$V$.</span> Given a basis and any vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in V">$\vec{v} \in V$,</span> there is a <strong>unique</strong> linear combination</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{v}.[NEWLINE]$$">$$\begin{align*}c_1\vec{v_1} + c_2\vec{v_2} + \cdots + c_n\vec{v_n} = \vec{v}.\end{align*}$$</span></p></div><p class="body-text">Just like in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> if a collection of vectors <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> spans a vector space <span class="tex-holder inline-math" data-source-tex="V">$V$</span> but one of the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> is a linear combination of the others, then we can remove that one without affecting the fact that the collection spans <span class="tex-holder inline-math" data-source-tex="V">$V$.</span> In this sense, a basis is just the right size: add any new vector to it and it&#x2019;ll stop being linearly independent, and remove any and it won&#x2019;t span <span class="tex-holder inline-math" data-source-tex="V">$V$.</span></p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">The primordial example of a basis is the vectors</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{e_1} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{array}\right], \vec{e_2} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right], ..., \vec{e_n} = \left[\begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array}\right] \in \mathbb{R}^n.[NEWLINE]$$">$$\begin{align*}\vec{e_1} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \end{array}\right], \vec{e_2} = \left[\begin{array}{c} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \end{array}\right], ..., \vec{e_n} = \left[\begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array}\right] \in \mathbb{R}^n.\end{align*}$$</span></p><p class="body-text">The <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> are linearly independent since they&#x2019;re already the rows of the identity matrix, and they certainly span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$:</span> given a vector <span class="tex-holder inline-math" data-source-tex="\vec{v} \in \mathbb{R}^n">$\vec{v} \in \mathbb{R}^n$,</span> we can immediately express <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> as a linear combination of the <span class="tex-holder inline-math" data-source-tex="\vec{e_i}">$\vec{e_i}$</span> (like we did at the start of the section).</p></div><p class="body-text">This basis is so common that we&#x2019;ll want a name for it &mdash; it&#x2019;s called the <strong>standard basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</strong>.</span> The name implies it&#x2019;s not the only one, though, and that&#x2019;s definitely the case. Let&#x2019;s take a look at some more unusual ones.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: another basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">Show that the vectors</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v_1} = \left[\begin{array}{c} 3 \\ 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right], \qquad \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ 1 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v_1} = \left[\begin{array}{c} 3 \\ 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 1 \\ 0 \\ 1 \end{array}\right], \qquad \vec{v_3} = \left[\begin{array}{c} 0 \\ 2 \\ 1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">form a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$</span> and express the vector</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = \left[\begin{array}{c} 4 \\ 1 \\ 0 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v} = \left[\begin{array}{c} 4 \\ 1 \\ 0 \end{array}\right]\end{align*}$$</span></p><p class="body-text">in this basis.</p><p class="body-text">While this is nominally a new kind of task, we&#x2019;ve been showing that vectors are linearly independent and spanning for a few sections now: showing that a linear transformation is one-to-one and onto amounts to showing that its columns are linearly independent and span the transformation&#x2019;s codomain. We do that by transposing the matrix and row reducing without swapping rows, so we might as well jump straight to that step now by placing our vectors as rows in a matrix. We have</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc} 3& 1& 2 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] &\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] & \qquad \vec{r_1} \ -\!\!= 3\vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 3 \end{array}\right] & \qquad \vec{r_3} \ -\!\!= 2\vec{r_1}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \ \times\!\!= \frac{1}{3}\\[NEWLINE][TAB]\left[\begin{array}{ccc} 0& 1& 0 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \ -\!\!= \vec{r_3} \\ \vec{r_1} \ +\!\!= \vec{r_3} \end{array},[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc} 3& 1& 2 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] &\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 2& 1 \end{array}\right] & \qquad \vec{r_1} \ -\!\!= 3\vec{r_2}\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 3 \end{array}\right] & \qquad \vec{r_3} \ -\!\!= 2\vec{r_1}\\[4px]\left[\begin{array}{ccc} 0& 1& -1 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \vec{r_3} \ \times\!\!= \frac{1}{3}\\[4px]\left[\begin{array}{ccc} 0& 1& 0 \\ 1& 0& 1 \\ 0& 0& 1 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \ -\!\!= \vec{r_3} \\ \vec{r_1} \ +\!\!= \vec{r_3} \end{array},\end{align*}$$</span></p><p class="body-text">and so all of the vectors are linearly independent and therefore span <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^3">$\mathbb{R}^3$.</span></p><p class="body-text">To express <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> in the basis, we&#x2019;re just trying to find a linear combination of the basis vectors that equals <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$.</span> We&#x2019;ve already solved that type of problem: it&#x2019;s just row reduction once again, this time with the <span class="tex-holder inline-math" data-source-tex="\vec{v_i}">$\vec{v_i}$</span> as columns.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{ccc|c} 3& 1& 0 & 4 \\ 1& 0& 2 & 1 \\ 2& 1& 1 & 0 \end{array}\right] & \\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 3& 1& 0 & 4 \\ 2& 1& 1 & 0 \end{array}\right] & \qquad \operatorname{swap} \vec{r_1}, \vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 1& -3 & -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \ -\!\!= 3\vec{r_1} \\ \vec{r_3} \ -\!\!= 2\vec{r_1} \end{array}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 3 & -3 \end{array}\right] & \qquad \vec{r_3} \ -\!\!= \vec{r_2}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_3} \ \times\!\!= \frac{1}{3}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_2} \ +\!\!= 6\vec{r_3}\\[NEWLINE][TAB]\left[\begin{array}{ccc|c} 1& 0& 0 & 3 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -3 \end{array}\right] & \qquad \vec{r_1} \ -\!\!= 2\vec{r_3}.[NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{ccc|c} 3& 1& 0 & 4 \\ 1& 0& 2 & 1 \\ 2& 1& 1 & 0 \end{array}\right] & \\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 3& 1& 0 & 4 \\ 2& 1& 1 & 0 \end{array}\right] & \qquad \operatorname{swap} \vec{r_1}, \vec{r_2}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 1& -3 & -2 \end{array}\right] & \qquad \begin{array}{l} \vec{r_2} \ -\!\!= 3\vec{r_1} \\ \vec{r_3} \ -\!\!= 2\vec{r_1} \end{array}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 3 & -3 \end{array}\right] & \qquad \vec{r_3} \ -\!\!= \vec{r_2}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& -6 & 1 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_3} \ \times\!\!= \frac{1}{3}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 2 & 1 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -1 \end{array}\right] & \qquad \vec{r_2} \ +\!\!= 6\vec{r_3}\\[4px]\left[\begin{array}{ccc|c} 1& 0& 0 & 3 \\ 0& 1& 0 & -5 \\ 0& 0& 1 & -3 \end{array}\right] & \qquad \vec{r_1} \ -\!\!= 2\vec{r_3}.\end{align*}$$</span></p><p class="body-text">In total, our linear combination is <span class="tex-holder inline-math" data-source-tex="\vec{v} = 3\vec{v_1} - 5\vec{v_2} - 3\vec{v_3}">$\vec{v} = 3\vec{v_1} - 5\vec{v_2} - 3\vec{v_3}$.</span> Geometrically, we can think of this expansion as meaning that the coordinates of <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> are <span class="tex-holder inline-math" data-source-tex="(3, -5, -3)">$(3, -5, -3)$</span> in a strange coordinate system where the axes are parallel to <span class="tex-holder inline-math" data-source-tex="\vec{v_1}">$\vec{v_1}$,</span> <span class="tex-holder inline-math" data-source-tex="\vec{v_2}">$\vec{v_2}$,</span> and <span class="tex-holder inline-math" data-source-tex="\vec{v_3}">$\vec{v_3}$.</span></p></div><p class="body-text">Let&#x2019;s dig into that coordinate system idea a little more. In <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$,</span> the standard basis produces the typical coordinate system we&#x2019;re used to, while other bases produce coordinate systems that are stretched and scaled, but still perfectly functional at assigning a unique coordinate pair to every point. </p><div class="desmos-border"><div id="coordinateSystems" class="desmos-container"></div></div><p class="body-text">Here, the purple grid shows the coordinates assigned by the basis <span class="tex-holder inline-math" data-source-tex="\left\{ \left[\begin{array}{c} -1 \\ 1 \end{array}\right], \left[\begin{array}{c} 2 \\ 1 \end{array}\right] \right\}">$\left\{ \left[\begin{array}{c} -1 \\ 1 \end{array}\right], \left[\begin{array}{c} 2 \\ 1 \end{array}\right] \right\}$.</span> The blue point is called <span class="tex-holder inline-math" data-source-tex="(3, 3)">$(3, 3)$</span> in the standard basis, but <span class="tex-holder inline-math" data-source-tex="(1, 2)">$(1, 2)$</span> in this alternate one.</p><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: another basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span></div><p class="body-text">Show that the vectors</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 0 \\ -1 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v_1} = \left[\begin{array}{c} 1 \\ 2 \end{array}\right], \qquad \vec{v_2} = \left[\begin{array}{c} 0 \\ -1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">form a basis for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$,</span> and express the vector</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = \left[\begin{array}{c} 3 \\ 8 \end{array}\right][NEWLINE]$$">$$\begin{align*}\vec{v} = \left[\begin{array}{c} 3 \\ 8 \end{array}\right]\end{align*}$$</span></p><p class="body-text">in this basis.</p></div><p class="body-text">Much like the key idea that matrix multiplication is function composition, let&#x2019;s state another critical notion that we&#x2019;ll return to throughout this section and future ones. The only reason <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> seems easier to work with than all of these new vector spaces is <strong>because it came equipped with a convenient basis</strong> &mdash; the standard one. If we want to bring the convenience of matrices and vectors to spaces that don&#x2019;t support them naturally &mdash; like <span class="tex-holder inline-math" data-source-tex="\mathbb{R}[x]">$\mathbb{R}[x]$</span> &mdash; then we need to choose our own basis.</p><p class="body-text">Let&#x2019;s say a vector space <span class="tex-holder inline-math" data-source-tex="V">$V$</span> has a basis <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_n}">$\vec{v_1}, ..., \vec{v_n}$.</span> Then expressing a vector <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> in this basis lets us evaluate a linear transformation by just knowing its action on the basis vectors:</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T(\vec{v}) &= T(c_1\vec{v_1} + \cdots + c_n\vec{v_n})\\[NEWLINE][TAB]&= c_1T(\vec{v_1}) + \cdots + c_nT(\vec{v_n}).[NEWLINE]\end{align*}">$$\begin{align*}T(\vec{v}) &= T(c_1\vec{v_1} + \cdots + c_n\vec{v_n})\\[4px]&= c_1T(\vec{v_1}) + \cdots + c_nT(\vec{v_n}).\end{align*}$$</span></p><p class="body-text">In <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> we did this in the particular case with <span class="tex-holder inline-math" data-source-tex="\vec{v_i} = \vec{e_i}">$\vec{v_i} = \vec{e_i}$</span> and <span class="tex-holder inline-math" data-source-tex="\vec{v} = \left[\begin{array}{c} c_1 \\ \vdots \\ c_n \end{array}\right]">$\vec{v} = \left[\begin{array}{c} c_1 \\ \vdots \\ c_n \end{array}\right]$,</span> but now the objects aren&#x2019;t necessarily vectors in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$.</span> They still often <em>function</em> like vectors in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$,</span> though, as the previous block of math shows. To emphasize the relationship and make vectors in more abstract vector spaces easier to work with, let&#x2019;s create some notation to help.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: coordinate vector</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="V">$V$</span> be a vector space, let <span class="tex-holder inline-math" data-source-tex="\vec{v} \in V">$\vec{v} \in V$,</span> and let <span class="tex-holder inline-math" data-source-tex="\vec{v_1}, ..., \vec{v_n}">$\vec{v_1}, ..., \vec{v_n}$</span> be a basis, denoted <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$.</span> Then there is a unique expression</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]\vec{v} = c_1\vec{v_1} + \cdots + c_n\vec{v_n},[NEWLINE]$$">$$\begin{align*}\vec{v} = c_1\vec{v_1} + \cdots + c_n\vec{v_n},\end{align*}$$</span></p><p class="body-text">and we define the <strong>coordinate vector</strong> of <span class="tex-holder inline-math" data-source-tex="\vec{v}">$\vec{v}$</span> as</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB][\vec{v}]_\mathcal{B} = \left[\begin{array}{c} c_1 \\ \vdots \\ c_n \end{array}\right].[NEWLINE]$$">$$\begin{align*}[\vec{v}]_\mathcal{B} = \left[\begin{array}{c} c_1 \\ \vdots \\ c_n \end{array}\right].\end{align*}$$</span></p></div><p class="body-text">So for example, if <span class="tex-holder inline-math" data-source-tex="V">$V$</span> is the space of polynomials with degree at most <span class="tex-holder inline-math" data-source-tex="3">$3$</span> and <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> is the basis <span class="tex-holder inline-math" data-source-tex="1, x, x^2, x^3">$1, x, x^2, x^3$</span> , then</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB][3 - x + 4x^3]_\mathcal{B} = \left[\begin{array}{c} 3 \\ -1 \\ 0 \\ 4 \end{array}\right].[NEWLINE]$$">$$\begin{align*}[3 - x + 4x^3]_\mathcal{B} = \left[\begin{array}{c} 3 \\ -1 \\ 0 \\ 4 \end{array}\right].\end{align*}$$</span></p><p class="body-text">The magic of coordinate vectors is that they let us define matrices, with the one caveat that those coordinate vectors only work when we choose a particular basis. To form the matrix for a linear transformation <span class="tex-holder inline-math" data-source-tex="T : V \to W">$T : V \to W$,</span> we choose a basis <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> for <span class="tex-holder inline-math" data-source-tex="V">$V$</span> and <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> for <span class="tex-holder inline-math" data-source-tex="W">$W$,</span> evaluate <span class="tex-holder inline-math" data-source-tex="T">$T$</span> on each of the vectors in <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$,</span> and then express each of those as coordinate vectors in <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$.</span> Then we place those as columns in a matrix <span class="tex-holder inline-math" data-source-tex="A">$A$,</span> at which point</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]A[\vec{v}]_\mathcal{B} = [T(\vec{v})]_\mathcal{C}.[NEWLINE]$$">$$\begin{align*}A[\vec{v}]_\mathcal{B} = [T(\vec{v})]_\mathcal{C}.\end{align*}$$</span></p><p class="body-text">That requires a whole lot of work to understand, so let&#x2019;s dig in.</p><div class="notes-ex notes-environment"><div class="notes-ex-title notes-title">Example: the matrix of a transformation</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="V">$V$</span> be the subspace of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}[x]">$\mathbb{R}[x]$</span> of polynomials with degree at most <span class="tex-holder inline-math" data-source-tex="3">$3$,</span> and let <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> be the basis <span class="tex-holder inline-math" data-source-tex="1, x, x^2, x^3">$1, x, x^2, x^3$</span> for <span class="tex-holder inline-math" data-source-tex="V">$V$.</span> Let <span class="tex-holder inline-math" data-source-tex="W">$W$</span> be the subspace of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}[x]">$\mathbb{R}[x]$</span> of polynomials with degree at most <span class="tex-holder inline-math" data-source-tex="2">$2$,</span> and let <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> be the basis <span class="tex-holder inline-math" data-source-tex="1, x, x^2">$1, x, x^2$</span> for <span class="tex-holder inline-math" data-source-tex="W">$W$.</span> Let <span class="tex-holder inline-math" data-source-tex="D : V \to W">$D : V \to W$</span> be the linear transformation given by differentiation. Find the matrix <span class="tex-holder inline-math" data-source-tex="A">$A$</span> for <span class="tex-holder inline-math" data-source-tex="D">$D$</span> with respect to these two bases and use it to evaluate <span class="tex-holder inline-math" data-source-tex="D(1 - 2x + x^3)">$D(1 - 2x + x^3)$.</span></p><p class="body-text">To begin, we just plug every one of the four basis vectors in <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> into <span class="tex-holder inline-math" data-source-tex="D">$D$,</span> resulting in <span class="tex-holder inline-math" data-source-tex="0">$0$,</span> <span class="tex-holder inline-math" data-source-tex="1">$1$,</span> <span class="tex-holder inline-math" data-source-tex="2x">$2x$,</span> and <span class="tex-holder inline-math" data-source-tex="3x^2">$3x^2$.</span> Then we write each as a coordinate vector in <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$,</span> which gives us</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB][0]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right] \qquad [1]_\mathcal{C} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right] \qquad [2x]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 2 \\ 0 \end{array}\right] \qquad [3x^2]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 0 \\ 3 \end{array}\right].[NEWLINE]$$">$$\begin{align*}[0]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 0 \\ 0 \end{array}\right] \qquad [1]_\mathcal{C} = \left[\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right] \qquad [2x]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 2 \\ 0 \end{array}\right] \qquad [3x^2]_\mathcal{C} = \left[\begin{array}{c} 0 \\ 0 \\ 3 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Assembling those into a matrix gives us</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]A = \left[\begin{array}{cccc} 0& 1& 0& 0 \\ 0& 0& 2& 0 \\ 0& 0& 0& 3 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}A = \left[\begin{array}{cccc} 0& 1& 0& 0 \\ 0& 0& 2& 0 \\ 0& 0& 0& 3 \end{array}\right].\end{align*}$$</span></p><p class="body-text">To actually use <span class="tex-holder inline-math" data-source-tex="A">$A$</span> to compute the effect of <span class="tex-holder inline-math" data-source-tex="D">$D$</span> on the vector (i.e. polynomial) <span class="tex-holder inline-math" data-source-tex="1 - 2x + x^3">$1 - 2x + x^3$,</span> we first write it as a coordinate vector using the basis <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$:</span></p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB][1 - 2x + x^3]_\mathcal{B} = \left[\begin{array}{c} 1 \\ -2 \\ 0 \\ 1 \end{array}\right].[NEWLINE]$$">$$\begin{align*}[1 - 2x + x^3]_\mathcal{B} = \left[\begin{array}{c} 1 \\ -2 \\ 0 \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Then we do matrix multiplication as usual.</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]A[1 - 2x + x^3]_\mathcal{B} &= \left[\begin{array}{cccc} 0& 1& 0& 0 \\ 0& 0& 2& 0 \\ 0& 0& 0& 3 \end{array}\right]\left[\begin{array}{c} 1 \\ -2 \\ 0 \\ 1 \end{array}\right]\\[NEWLINE][TAB]&= \left[\begin{array}{c} -2 \\ 0 \\ 3 \end{array}\right].[NEWLINE]\end{align*}">$$\begin{align*}A[1 - 2x + x^3]_\mathcal{B} &= \left[\begin{array}{cccc} 0& 1& 0& 0 \\ 0& 0& 2& 0 \\ 0& 0& 0& 3 \end{array}\right]\left[\begin{array}{c} 1 \\ -2 \\ 0 \\ 1 \end{array}\right]\\[4px]&= \left[\begin{array}{c} -2 \\ 0 \\ 3 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Finally, we interpret this as a coordinate vector in <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$,</span> which corresponds to the polynomial <span class="tex-holder inline-math" data-source-tex="-2 + 3x^2">$-2 + 3x^2$,</span> which is successfully <span class="tex-holder inline-math" data-source-tex="D(1 - 2x + x^3)">$D(1 - 2x + x^3)$.</span> Although the notation is a little bit clunkier and the process is a little bit longer, this is just a return to our old saying that matrix multiplication is function evaluation. Since linear transformations are defined by their actions on just basis vectors, we can make a perfect analogy to <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> and recover all of our matrix techniques in the process.</p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: the matrix of a transformation</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> be the basis</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]\left[\begin{array}{cc} 1& 0 \\ 0& 0 \end{array}\right], \left[\begin{array}{cc} 0& 1 \\ 0& 0 \end{array}\right], \left[\begin{array}{cc} 0& 0 \\ 1& 0 \end{array}\right], \left[\begin{array}{cc} 0& 0 \\ 0& 1 \end{array}\right][NEWLINE]\end{align*}">$$\begin{align*}\left[\begin{array}{cc} 1& 0 \\ 0& 0 \end{array}\right], \left[\begin{array}{cc} 0& 1 \\ 0& 0 \end{array}\right], \left[\begin{array}{cc} 0& 0 \\ 1& 0 \end{array}\right], \left[\begin{array}{cc} 0& 0 \\ 0& 1 \end{array}\right]\end{align*}$$</span></p><p class="body-text">for <span class="tex-holder inline-math" data-source-tex="M_{2 \times 2}(\mathbb{R})">$M_{2 \times 2}(\mathbb{R})$</span> and let <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> be the basis <span class="tex-holder inline-math" data-source-tex="\left[\begin{array}{c} 1 \\ 0 \end{array}\right], \left[\begin{array}{c} 0 \\ 1 \end{array}\right]">$\left[\begin{array}{c} 1 \\ 0 \end{array}\right], \left[\begin{array}{c} 0 \\ 1 \end{array}\right]$</span> for <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^2">$\mathbb{R}^2$.</span> Let <span class="tex-holder inline-math" data-source-tex="T : M_{2 \times 2}(\mathbb{R}) \to \mathbb{R}^2">$T : M_{2 \times 2}(\mathbb{R}) \to \mathbb{R}^2$</span> be the linear transformation defined by</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]T(E) = E \left[\begin{array}{c} -2 \\ 1 \end{array}\right].[NEWLINE]$$">$$\begin{align*}T(E) = E \left[\begin{array}{c} -2 \\ 1 \end{array}\right].\end{align*}$$</span></p><p class="body-text">Find the matrix <span class="tex-holder inline-math" data-source-tex="A">$A$</span> for <span class="tex-holder inline-math" data-source-tex="T">$T$</span> with respect to these two bases and use it to evaluate</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="\begin{align*}[NEWLINE][TAB]T\left( \left[\begin{array}{cc} 1& 3 \\ -1& 0 \end{array}\right] \right).[NEWLINE]\end{align*}">$$\begin{align*}T\left( \left[\begin{array}{cc} 1& 3 \\ -1& 0 \end{array}\right] \right).\end{align*}$$</span></p></div><p class="body-text">One immediate upshot of coordinate vectors is that they let us pin down how many vectors make up a basis. Suppose a vector space <span class="tex-holder inline-math" data-source-tex="V">$V$</span> has one basis <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> with <span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors and another basis <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> with <span class="tex-holder inline-math" data-source-tex="m">$m$</span> vectors. Then we can write the vectors of <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> as coordinate vectors in <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$,</span> which live in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> since <span class="tex-holder inline-math" data-source-tex="\mathcal{B}">$\mathcal{B}$</span> has <span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors. But any more than <span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors in <span class="tex-holder inline-math" data-source-tex="\mathbb{R}^n">$\mathbb{R}^n$</span> can&#x2019;t be linearly independent, and any fewer can&#x2019;t span, so <span class="tex-holder inline-math" data-source-tex="\mathcal{C}">$\mathcal{C}$</span> must have exactly <span class="tex-holder inline-math" data-source-tex="n">$n$</span> vectors too. In short, any two bases for a vector space have the same size, and it&#x2019;s worth giving that invariant a name.</p><div class="notes-def notes-environment"><div class="notes-def-title notes-title">Definition: dimension</div><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="V">$V$</span> be a vector space. The <strong>dimension of <span class="tex-holder inline-math" data-source-tex="V">$V$</strong>,</span> written <span class="tex-holder inline-math" data-source-tex="\dim V">$\dim V$,</span> is the number of vectors in any basis of <span class="tex-holder inline-math" data-source-tex="V">$V$.</span> If <span class="tex-holder inline-math" data-source-tex="\dim V">$\dim V$</span> is finite, we say <span class="tex-holder inline-math" data-source-tex="V">$V$</span> is <strong>finite-dimensional</strong>, and if not, we say <span class="tex-holder inline-math" data-source-tex="V">$V$</span> is infinite-dimensional. Finally, we define <span class="tex-holder inline-math" data-source-tex="\dim \{\vec{0}\} = 0">$\dim \{\vec{0}\} = 0$.</span></p></div><div class="notes-exc notes-environment"><div class="notes-exc-title notes-title">Exercise: dimension</div><p class="body-text">Find <span class="tex-holder inline-math" data-source-tex="\dim V">$\dim V$</span> for the following vector spaces <span class="tex-holder inline-math" data-source-tex="V">$V$.</span></p><p class="body-text numbered-list-item">1. <span class="tex-holder inline-math" data-source-tex="V = \mathbb{R}^4">$V = \mathbb{R}^4$.</span></p><p class="body-text numbered-list-item">2. <span class="tex-holder inline-math" data-source-tex="V">$V$</span> is the subspace of <span class="tex-holder inline-math" data-source-tex="\mathbb{R}[x]">$\mathbb{R}[x]$</span> of polynomials with degree at most <span class="tex-holder inline-math" data-source-tex="4">$4$.</span></p><p class="body-text numbered-list-item">3. <span class="tex-holder inline-math" data-source-tex="V = \mathbb{R}[x]">$V = \mathbb{R}[x]$.</span></p><p class="body-text numbered-list-item">4. <span class="tex-holder inline-math" data-source-tex="V = M_{2 \times 3}(\mathbb{R})">$V = M_{2 \times 3}(\mathbb{R})$.</span></p></div><p class="body-text">In the next section, we&#x2019;ll tie up the last remaining loose ends: how to easily change from one basis to another, and why exactly the kernel and image are so important and closely related.</p><div class="text-buttons nav-buttons"><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button nav-button next-nav-button" type="button" tabindex="-1">Next</button></div></div></section></main>